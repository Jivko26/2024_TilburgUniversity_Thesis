{"cells":[{"cell_type":"markdown","metadata":{"id":"amMZWTSenDs5"},"source":["# 1. Initial Steps and Data Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FEnaHANQAp3p"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import random_split"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1715000176546,"user":{"displayName":"Jivko Parapanov","userId":"13549335107747025520"},"user_tz":-120},"id":"5XnG1MZ_As85","outputId":"b4a4ed4d-7869-43b4-f386-44c4a897113d"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","SEED = 42\n","\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lnUUpJqRAwPj"},"outputs":[],"source":["DATA_DIRECTORY = 'Data/hyperaktiv_with_controls/hyperaktiv_with_controls/'\n","VALID_IDs = [1, 3, 5, 7, 9, 11, 15, 19, 20, 21, 22, 23, 24, 27, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 68, 71, 73, 75, 77, 78, 79, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 93, 94, 95, 97, 98, 101, 104, 105]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":507},"executionInfo":{"elapsed":3923,"status":"ok","timestamp":1715000180463,"user":{"displayName":"Jivko Parapanov","userId":"13549335107747025520"},"user_tz":-120},"id":"j5CUst8WAzKJ","outputId":"6070eef6-cfba-490b-f0ee-bf283e538f87"},"outputs":[],"source":["demographic_data = pd.read_csv(f'{DATA_DIRECTORY}patient_info.csv', sep=';')\n","#plot the balance of the ADHD class in the demographic_data for every record that has ID in VALID_IDs. Insert labels and make it more appealing\n","demographic_data = demographic_data[demographic_data['ID'].isin(VALID_IDs)]\n","# Extract labels for these IDs\n","labels = demographic_data['ADHD'].values\n","\n","# Output the labels to verify\n","print(labels)\n","\n","demographic_data['ADHD'].value_counts().plot(kind='bar', title='ADHD class balance in the dataset')\n","plt.xticks([0, 1], ['Control', 'ADHD'], rotation=0)\n","plt.ylabel('Number of records')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1715000180464,"user":{"displayName":"Jivko Parapanov","userId":"13549335107747025520"},"user_tz":-120},"id":"kj_rZbieA0qe","outputId":"872bfe9c-2675-4d41-f86c-08439d683d80"},"outputs":[],"source":["# I want to noe the IDS of the control and ADHD patients\n","control_ids = demographic_data[demographic_data['ADHD'] == 0]['ID'].values\n","adhd_ids = demographic_data[demographic_data['ADHD'] == 1]['ID'].values\n","\n","print(f'Number of control patients: {len(control_ids)}; IDS: {control_ids}')\n","print(f'Number of ADHD patients: {len(adhd_ids)}; IDS: {adhd_ids}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xfLJYY58UeWH"},"outputs":[],"source":["from sklearn.model_selection import StratifiedShuffleSplit\n","\n","def enhanced_split_dataset(ids, labels, train_ratio=0.80, val_ratio=0.10, test_ratio=0.10, random_seed=42):\n","    # Convert ratios to a useable format for StratifiedShuffleSplit\n","    splits = StratifiedShuffleSplit(n_splits=1, test_size=test_ratio, random_state=random_seed)\n","\n","    # Remaining ratio is for validation\n","    remaining_ratio = 1.0 - test_ratio\n","    val_relative_ratio = val_ratio / remaining_ratio\n","\n","    # First split to separate out the test set\n","    train_val_ids, test_ids = next(splits.split(ids, labels))\n","\n","    # Second split to separate out the validation set from the remaining train set\n","    train_val_split = StratifiedShuffleSplit(n_splits=1, test_size=val_relative_ratio, random_state=random_seed)\n","    train_ids, val_ids = next(train_val_split.split(ids[train_val_ids], labels[train_val_ids]))\n","\n","    # Convert indices to actual IDs\n","    train_ids = ids[train_ids]\n","    val_ids = ids[val_ids]\n","    test_ids = ids[test_ids]\n","\n","    return train_ids, val_ids, test_ids\n","\n","# Example usage:\n","# Assume labels is an array of labels corresponding to VALID_IDs in the same order\n","train_ids, val_ids, test_ids = enhanced_split_dataset(np.array(VALID_IDs), np.array(labels))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":582,"status":"ok","timestamp":1715000181031,"user":{"displayName":"Jivko Parapanov","userId":"13549335107747025520"},"user_tz":-120},"id":"OJr2s-TYBRXN","outputId":"e934e71b-502c-4697-efaf-37d10bc7a3f8"},"outputs":[],"source":["demographic_data_train = demographic_data[demographic_data['ID'].isin(train_ids)]\n","demographic_data_train['ADHD'].value_counts().plot(kind='bar', title='ADHD class balance in the train dataset')\n","plt.xticks([0, 1], ['Control', 'ADHD'], rotation=0)\n","plt.ylabel('Number of records')\n","plt.show()\n","\n","demographic_data_test = demographic_data[demographic_data['ID'].isin(test_ids)]\n","demographic_data_test['ADHD'].value_counts().plot(kind='bar', title='ADHD class balance in the test dataset')\n","plt.xticks([0, 1], ['Control', 'ADHD'], rotation=0)\n","plt.ylabel('Number of records')\n","plt.show()\n","\n","demographic_data_val = demographic_data[demographic_data['ID'].isin(val_ids)]\n","demographic_data_val['ADHD'].value_counts().plot(kind='bar', title='ADHD class balance in the valdiation dataset')\n","plt.xticks([0, 1], ['Control', 'ADHD'], rotation=0)\n","plt.ylabel('Number of records')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ss8WatgzBTVX"},"outputs":[],"source":["\n","def load_data(sample, demographic_data):\n","    patients_data = {}  # Dictionary to store data\n","\n","    for patient_id in sample:\n","        hrv_data = pd.read_csv(f'{DATA_DIRECTORY}/hrv_data/patient_hr_{patient_id}.csv', sep=';')\n","        activity_data = pd.read_csv(f'{DATA_DIRECTORY}/activity_data/patient_activity_{patient_id}.csv', sep=';')\n","        labels =  demographic_data[demographic_data['ID'] == patient_id]['ADHD'].values[0]  # Get the ADHD label for the patient\n","\n","    # # Convert TIMESTAMP to datetime\n","    #     hrv_data['TIMESTAMP'] = pd.to_datetime(hrv_data['TIMESTAMP'], errors='coerce')\n","    #     activity_data['TIMESTAMP'] = pd.to_datetime(activity_data['TIMESTAMP'], errors='coerce')\n","\n","    # Setting TIMESTAMP as index and checking for NaNs in data columns\n","        df_hrv = pd.DataFrame(data=hrv_data).set_index('TIMESTAMP')\n","        df_activity = pd.DataFrame(data=activity_data).set_index('TIMESTAMP')\n","\n","    # # Fill NaNs in HRV and Activity before resampling\n","    #     df_hrv['HRV'] = df_hrv['HRV'].fillna(method='ffill')  # Forward fill as an example\n","    #     df_activity['ACTIVITY'] = df_activity['ACTIVITY'].fillna(method='ffill')  # Forward fill as an example\n","\n","    # # Now resample\n","    #     df_hrv = df_hrv.resample('1T').mean()\n","    #     df_activity = df_activity.resample('1T').mean()\n","\n","    # Trim datasets to the same length\n","        min_length = min(len(df_hrv), len(df_activity))\n","        df_hrv = df_hrv.iloc[:min_length]\n","        df_activity = df_activity.iloc[:min_length]\n","\n","    # Store in dictionary\n","        patients_data[patient_id] = {\n","        'hrv': df_hrv,\n","        'activity': df_activity,\n","        'adhd': labels\n","        }\n","\n","    return patients_data\n","\n","\n","train_data = load_data(train_ids, demographic_data=demographic_data_train)\n","test_data = load_data(test_ids, demographic_data=demographic_data_test)\n","val_data = load_data(val_ids, demographic_data=demographic_data_val)\n","\n","all_data = {\n","    'train':  train_data,\n","    'val': val_data,\n","    'test': test_data\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1715000349782,"user":{"displayName":"Jivko Parapanov","userId":"13549335107747025520"},"user_tz":-120},"id":"hrHH5KX2Xi5Q","outputId":"c65dbd8c-bb88-458e-9100-4f215e99fcb6"},"outputs":[],"source":["# print shapes\n","print(\"Train Patients: \")\n","for patient_id, data in all_data['train'].items():\n","    print(f'Patient ID: {patient_id}; HRV shape: {data[\"hrv\"].shape}; Activity shape: {data[\"activity\"].shape}')\n","\n","print(\"---------------\")\n","print(\"Validation Patients: \")\n","# print shapes\n","for patient_id, data in all_data['val'].items():\n","    print(f'Patient ID: {patient_id}; HRV shape: {data[\"hrv\"].shape}; Activity shape: {data[\"activity\"].shape}')\n","\n","print(\"---------------\")\n","print(\"Test Patients: \")\n","# print shapes\n","for patient_id, data in all_data['test'].items():\n","    print(f'Patient ID: {patient_id}; HRV shape: {data[\"hrv\"].shape}; Activity shape: {data[\"activity\"].shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rKsLz0BdGG9u"},"outputs":[],"source":["\n","\n","def segment_data(data, window_size, step_size):\n","    segments = []\n","    for start in range(0, len(data) - window_size + 1, step_size):\n","        segment = data[start:start + window_size]\n","        segments.append(segment)\n","    return segments\n","\n","def normalize_data(data):\n","    scaler = RobustScaler()\n","    scaled_data = scaler.fit_transform(data)\n","    return scaled_data\n","\n","def preprocessData_create_windows(config, data):\n","    window_size = config['window_size']\n","    step_size = window_size // 2\n","    processed_data = {}\n","\n","    for patient_id, patient_data in data.items():\n","        # Segment and normalize HRV and activity data\n","        hrv_segments = segment_data(patient_data['hrv']['HRV'], window_size, step_size)\n","        activity_segments = segment_data(patient_data['activity']['ACTIVITY'], window_size, step_size)\n","        hrv_normalized = normalize_data(np.array(hrv_segments).reshape(-1, window_size)).reshape(-1, window_size)\n","        activity_normalized = normalize_data(np.array(activity_segments).reshape(-1, window_size)).reshape(-1, window_size)\n","        labels_repeated = np.repeat(patient_data['adhd'], len(hrv_normalized))\n","\n","        processed_data[patient_id] = {'hrv': hrv_normalized, 'activity': activity_normalized, 'labels': labels_repeated}\n","\n","    return processed_data\n","\n","def preprocessData_no_windows(config, data):\n","    processed_data = {}\n","\n","    for patient_id, patient_data in data.items():\n","        hrv_normalized = normalize_data(np.array(patient_data['hrv']['HRV']).reshape(-1, 1)).reshape(-1, 1)\n","        activity_normalized = normalize_data(np.array(patient_data['activity']['ACTIVITY']).reshape(-1, 1)).reshape(-1, 1)\n","        labels_repeated = np.repeat(patient_data['adhd'], len(hrv_normalized))\n","\n","        processed_data[patient_id] = {'hrv': hrv_normalized, 'activity': activity_normalized, 'labels': labels_repeated}\n","\n","    return processed_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"akyeBPhUGMHp"},"outputs":[],"source":["class PatientDataset(Dataset):\n","    def __init__(self, patients_data):\n","        self.patients_data = patients_data\n","        self.patient_ids = list(patients_data.keys())\n","        self.data = [(patient_id, idx) for patient_id in self.patient_ids for idx in range(len(patients_data[patient_id]['hrv']))]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        patient_id, data_idx = self.data[idx]\n","        patient_data = self.patients_data[patient_id]\n","\n","        hrv_data = torch.tensor(patient_data['hrv'][data_idx], dtype=torch.float32)\n","        activity_data = torch.tensor(patient_data['activity'][data_idx], dtype=torch.float32)\n","        label = torch.tensor(patient_data['labels'][data_idx], dtype=torch.float32)\n","\n","        return hrv_data, activity_data, label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2386,"status":"ok","timestamp":1715007087298,"user":{"displayName":"Jivko Parapanov","userId":"13549335107747025520"},"user_tz":-120},"id":"JidlW6I5VzlC","outputId":"f6eb635d-f9c1-49a5-a2de-875d663c2050"},"outputs":[],"source":["def plot_all_configs(histories):\n","    for config_id, history in histories.items():\n","        plt.figure(figsize=(12, 5))\n","        plt.subplot(1, 2, 1)\n","        plt.plot(history['train_loss'], label='Train Loss')\n","        plt.plot(history['val_loss'], label='Validation Loss')\n","        plt.title(f'Config {config_id} - Loss Over Epochs')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Loss')\n","        plt.legend()\n","\n","        plt.subplot(1, 2, 2)\n","        plt.plot(history['train_acc'], label='Train Accuracy')\n","        plt.plot(history['val_acc'], label='Validation Accuracy')\n","        plt.title(f'Config {config_id} - Accuracy Over Epochs')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Accuracy')\n","        plt.legend()\n","\n","        plt.show()\n","\n","# Plotting all configurations after running all experiments\n","plot_all_configs(config_histories)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SCODQhYeH4rx"},"outputs":[],"source":["# Convert results to DataFrame and save to CSV\n","results_df = pd.DataFrame(results)\n","results_df.to_csv('results_batch05_best_tunned_no_windows.csv', index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
